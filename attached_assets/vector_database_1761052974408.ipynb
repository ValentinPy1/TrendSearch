{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5755892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Vector Database for Keywords\n",
    "# This notebook creates a vector database for keyword search and similarity matching\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a31f4daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 56130 keywords from unique_keywords.csv\n",
      "Columns: ['Keyword']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat brain booster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corporate startup partnerships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banjo for sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>student isolation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>funeral monument pricing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Keyword\n",
       "0               cat brain booster\n",
       "1  corporate startup partnerships\n",
       "2                  banjo for sale\n",
       "3               student isolation\n",
       "4        funeral monument pricing"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and prepare the keywords data\n",
    "def load_keywords_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load keywords data from CSV file\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Loaded {len(df)} keywords from {file_path}\")\n",
    "        print(f\"Columns: {list(df.columns)}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the keywords data\n",
    "keywords_df = load_keywords_data('unique_keywords.csv')\n",
    "keywords_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fd59a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'all-MiniLM-L6-v2' loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the sentence transformer model\n",
    "def initialize_model(model_name: str = 'all-MiniLM-L6-v2'):\n",
    "    \"\"\"Initialize the sentence transformer model for embeddings\"\"\"\n",
    "    try:\n",
    "        model = SentenceTransformer(model_name)\n",
    "        print(f\"Model '{model_name}' loaded successfully!\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "# Initialize the model\n",
    "model = initialize_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "169b130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Database Class\n",
    "class KeywordVectorDatabase:\n",
    "    \"\"\"Vector database for keyword search and similarity matching\"\"\"\n",
    "    \n",
    "    def __init__(self, model, keywords_df: pd.DataFrame):\n",
    "        self.model = model\n",
    "        self.keywords_df = keywords_df\n",
    "        self.keywords = keywords_df['Keyword'].tolist()\n",
    "        self.embeddings = None\n",
    "        self.database_path = '/home/valentin/Home/Pioneers/InnovationMachine/vector_database.pkl'\n",
    "        \n",
    "    def create_embeddings(self, save_to_disk: bool = True):\n",
    "        \"\"\"Create embeddings for all keywords\"\"\"\n",
    "        print(\"Creating embeddings for keywords...\")\n",
    "        try:\n",
    "            # Create embeddings for all keywords\n",
    "            self.embeddings = self.model.encode(self.keywords)\n",
    "            print(f\"Created embeddings with shape: {self.embeddings.shape}\")\n",
    "            \n",
    "            if save_to_disk:\n",
    "                self.save_database()\n",
    "                \n",
    "            return self.embeddings\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating embeddings: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def save_database(self):\n",
    "        \"\"\"Save the vector database to disk\"\"\"\n",
    "        try:\n",
    "            database = {\n",
    "                'keywords': self.keywords,\n",
    "                'embeddings': self.embeddings,\n",
    "                'keywords_df': self.keywords_df\n",
    "            }\n",
    "            with open(self.database_path, 'wb') as f:\n",
    "                pickle.dump(database, f)\n",
    "            print(f\"Database saved to {self.database_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving database: {e}\")\n",
    "    \n",
    "    def load_database(self):\n",
    "        \"\"\"Load the vector database from disk\"\"\"\n",
    "        try:\n",
    "            if os.path.exists(self.database_path):\n",
    "                with open(self.database_path, 'rb') as f:\n",
    "                    database = pickle.load(f)\n",
    "                self.keywords = database['keywords']\n",
    "                self.embeddings = database['embeddings']\n",
    "                self.keywords_df = database['keywords_df']\n",
    "                print(f\"Database loaded from {self.database_path}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"No existing database found\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading database: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def search_similar_keywords(self, query: str, n: int = 10) -> pd.DataFrame:\n",
    "        \"\"\"Search for n most similar keywords to the query\"\"\"\n",
    "        try:\n",
    "            if self.embeddings is None:\n",
    "                print(\"No embeddings found. Please create embeddings first.\")\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "            # Create embedding for the query\n",
    "            query_embedding = self.model.encode([query])\n",
    "            \n",
    "            # Calculate cosine similarities\n",
    "            similarities = cosine_similarity(query_embedding, self.embeddings)[0]\n",
    "            \n",
    "            # Get top n most similar keywords\n",
    "            top_indices = np.argsort(similarities)[::-1][:n]\n",
    "            \n",
    "            # Create results dataframe\n",
    "            results = []\n",
    "            for idx in top_indices:\n",
    "                keyword_data = self.keywords_df.iloc[idx].copy()\n",
    "                keyword_data['similarity_score'] = similarities[idx]\n",
    "                results.append(keyword_data)\n",
    "            \n",
    "            results_df = pd.DataFrame(results)\n",
    "            return results_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error searching keywords: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "# Initialize the vector database\n",
    "vector_db = KeywordVectorDatabase(model, keywords_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc4419a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new vector database...\n",
      "Creating embeddings for keywords...\n",
      "Created embeddings with shape: (56130, 384)\n",
      "Database saved to /home/valentin/Home/Pioneers/InnovationMachine/vector_database.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create or load the vector database\n",
    "def setup_vector_database():\n",
    "    \"\"\"Setup the vector database - create embeddings or load from disk\"\"\"\n",
    "    # Try to load existing database first\n",
    "    print(\"Creating new vector database...\")\n",
    "    vector_db.create_embeddings()\n",
    "    \n",
    "    return vector_db\n",
    "\n",
    "# Setup the database\n",
    "db = setup_vector_database()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "760ead7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the vector database with sample queries...\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Main function to retrieve most relevant keywords\n",
    "def get_most_relevant_keywords(text_query: str, n: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieve the n most relevant keywords for a given text string\n",
    "    \n",
    "    Args:\n",
    "        text_query (str): The text string to search for similar keywords\n",
    "        n (int): Number of most relevant keywords to return (default: 10)\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the most relevant keywords with similarity scores\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = db.search_similar_keywords(text_query, n)\n",
    "        if not results.empty:\n",
    "            print(f\"Found {len(results)} most relevant keywords for: '{text_query}'\")\n",
    "            # Display key columns for better readability\n",
    "            display_cols = ['keyword', 'similarity_score', 'search_volume', 'competition', 'cpc']\n",
    "            available_cols = [col for col in display_cols if col in results.columns]\n",
    "            print(f\"\\nTop {n} most relevant keywords:\")\n",
    "            print(results[available_cols].to_string(index=False))\n",
    "        else:\n",
    "            print(\"No results found\")\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving keywords: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Test the function with some sample queries\n",
    "print(\"Testing the vector database with sample queries...\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebf88c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: 'artificial intelligence machine learning'\n",
      "--------------------------------------------------\n",
      "Found 5 most relevant keywords for: 'artificial intelligence machine learning'\n",
      "\n",
      "Top 5 most relevant keywords:\n",
      " similarity_score\n",
      "         0.832354\n",
      "         0.721266\n",
      "         0.672322\n",
      "         0.657029\n",
      "         0.652755\n",
      "\n",
      "\n",
      "Query: 'health nutrition fitness'\n",
      "--------------------------------------------------\n",
      "Found 5 most relevant keywords for: 'health nutrition fitness'\n",
      "\n",
      "Top 5 most relevant keywords:\n",
      " similarity_score\n",
      "         0.730558\n",
      "         0.723464\n",
      "         0.717951\n",
      "         0.713488\n",
      "         0.702746\n",
      "\n",
      "\n",
      "Query: 'business marketing strategy'\n",
      "--------------------------------------------------\n",
      "Found 5 most relevant keywords for: 'business marketing strategy'\n",
      "\n",
      "Top 5 most relevant keywords:\n",
      " similarity_score\n",
      "         0.925557\n",
      "         0.835108\n",
      "         0.788846\n",
      "         0.784925\n",
      "         0.771821\n",
      "\n",
      "\n",
      "Query: 'technology innovation startup'\n",
      "--------------------------------------------------\n",
      "Found 5 most relevant keywords for: 'technology innovation startup'\n",
      "\n",
      "Top 5 most relevant keywords:\n",
      " similarity_score\n",
      "         0.768638\n",
      "         0.760575\n",
      "         0.726493\n",
      "         0.711076\n",
      "         0.678931\n",
      "\n",
      "\n",
      "Query: 'data analytics insights'\n",
      "--------------------------------------------------\n",
      "Found 5 most relevant keywords for: 'data analytics insights'\n",
      "\n",
      "Top 5 most relevant keywords:\n",
      " similarity_score\n",
      "         0.925090\n",
      "         0.897551\n",
      "         0.813093\n",
      "         0.804797\n",
      "         0.800873\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test queries\n",
    "test_queries = [\n",
    "    \"artificial intelligence machine learning\",\n",
    "    \"health nutrition fitness\",\n",
    "    \"business marketing strategy\",\n",
    "    \"technology innovation startup\",\n",
    "    \"data analytics insights\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(\"-\" * 50)\n",
    "    results = get_most_relevant_keywords(query, n=5)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3dd122a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Database Statistics:\n",
      "==============================\n",
      "total_keywords: 56130\n",
      "embedding_dimension: 384\n",
      "database_size_mb: 83.64491939544678\n"
     ]
    }
   ],
   "source": [
    "# Additional utility functions\n",
    "def get_keyword_info(keyword: str) -> dict:\n",
    "    \"\"\"Get detailed information about a specific keyword\"\"\"\n",
    "    try:\n",
    "        keyword_data = db.keywords_df[db.keywords_df['keyword'] == keyword]\n",
    "        if not keyword_data.empty:\n",
    "            return keyword_data.iloc[0].to_dict()\n",
    "        else:\n",
    "            return {\"error\": f\"Keyword '{keyword}' not found\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error retrieving keyword info: {e}\"}\n",
    "\n",
    "def get_database_stats() -> dict:\n",
    "    \"\"\"Get statistics about the vector database\"\"\"\n",
    "    try:\n",
    "        stats = {\n",
    "            \"total_keywords\": len(db.keywords),\n",
    "            \"embedding_dimension\": db.embeddings.shape[1] if db.embeddings is not None else 0,\n",
    "            \"database_size_mb\": os.path.getsize(db.database_path) / (1024 * 1024) if os.path.exists(db.database_path) else 0\n",
    "        }\n",
    "        return stats\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error getting stats: {e}\"}\n",
    "\n",
    "# Display database statistics\n",
    "print(\"Vector Database Statistics:\")\n",
    "print(\"=\" * 30)\n",
    "stats = get_database_stats()\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aeabb317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VECTOR DATABASE USAGE EXAMPLES\n",
      "============================================================\n",
      "\n",
      "# Basic usage:\n",
      "results = get_most_relevant_keywords(\"your search query\", n=10)\n",
      "\n",
      "# Get specific keyword information:\n",
      "keyword_info = get_keyword_info(\"specific keyword\")\n",
      "\n",
      "# Get database statistics:\n",
      "stats = get_database_stats()\n",
      "\n",
      "# The main function returns a pandas DataFrame with:\n",
      "# - keyword: The keyword text\n",
      "# - similarity_score: Cosine similarity score (0-1)\n",
      "# - search_volume: Search volume data\n",
      "# - competition: Competition level\n",
      "# - cpc: Cost per click\n",
      "# - All other columns from the original keywords data\n",
      "\n",
      "\n",
      "Vector database setup complete! ðŸš€\n",
      "You can now use get_most_relevant_keywords(query, n) to find similar keywords.\n"
     ]
    }
   ],
   "source": [
    "# Example usage and documentation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VECTOR DATABASE USAGE EXAMPLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "# Basic usage:\n",
    "results = get_most_relevant_keywords(\"your search query\", n=10)\n",
    "\n",
    "# Get specific keyword information:\n",
    "keyword_info = get_keyword_info(\"specific keyword\")\n",
    "\n",
    "# Get database statistics:\n",
    "stats = get_database_stats()\n",
    "\n",
    "# The main function returns a pandas DataFrame with:\n",
    "# - keyword: The keyword text\n",
    "# - similarity_score: Cosine similarity score (0-1)\n",
    "# - search_volume: Search volume data\n",
    "# - competition: Competition level\n",
    "# - cpc: Cost per click\n",
    "# - All other columns from the original keywords data\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nVector database setup complete! ðŸš€\")\n",
    "print(\"You can now use get_most_relevant_keywords(query, n) to find similar keywords.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e00436f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 most relevant keywords for: '\n",
      "Build next apple watch\n",
      "'\n",
      "\n",
      "Top 10 most relevant keywords:\n",
      " similarity_score\n",
      "         0.607947\n",
      "         0.605693\n",
      "         0.582254\n",
      "         0.571385\n",
      "         0.555391\n",
      "         0.550626\n",
      "         0.544932\n",
      "         0.543916\n",
      "         0.542133\n",
      "         0.541360\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20672</th>\n",
       "      <td>buy smartwatch</td>\n",
       "      <td>0.607947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39307</th>\n",
       "      <td>generation smartwatch</td>\n",
       "      <td>0.605693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36142</th>\n",
       "      <td>display for watches</td>\n",
       "      <td>0.582254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27003</th>\n",
       "      <td>custom watchmaker</td>\n",
       "      <td>0.571385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>watch repair</td>\n",
       "      <td>0.555391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16356</th>\n",
       "      <td>race smartwatch</td>\n",
       "      <td>0.550626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27083</th>\n",
       "      <td>gps running watch</td>\n",
       "      <td>0.544932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42761</th>\n",
       "      <td>running watch</td>\n",
       "      <td>0.543916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9164</th>\n",
       "      <td>running watch price</td>\n",
       "      <td>0.542133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25702</th>\n",
       "      <td>running watch sale</td>\n",
       "      <td>0.541360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Keyword  similarity_score\n",
       "20672         buy smartwatch          0.607947\n",
       "39307  generation smartwatch          0.605693\n",
       "36142    display for watches          0.582254\n",
       "27003      custom watchmaker          0.571385\n",
       "2351            watch repair          0.555391\n",
       "16356        race smartwatch          0.550626\n",
       "27083      gps running watch          0.544932\n",
       "42761          running watch          0.543916\n",
       "9164     running watch price          0.542133\n",
       "25702     running watch sale          0.541360"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "Build next apple watch\n",
    "\"\"\"\n",
    "\n",
    "get_most_relevant_keywords(query, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327a193d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
